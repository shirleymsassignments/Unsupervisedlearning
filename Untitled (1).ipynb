{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Part 2:  Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the URL below with the raw URL of your CSV file\n",
    "url = 'https://github.com/shirleymsassignments/Unsupervisedlearning/blob/main/main_data.csv'\n",
    "data = pd.read_csv(url, sep='\\t', error_bad_lines=False)  # For TSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        <!DOCTYPE html>\n",
      "0                                                 <html\n",
      "1                                             lang=\"en\"\n",
      "2       data-color-mode=\"auto\" data-light-theme=\"lig...\n",
      "3       data-a11y-animated-images=\"system\" data-a11y...\n",
      "4                                                     >\n",
      "...                                                 ...\n",
      "1601                                             </div>\n",
      "1602      <div id=\"js-global-screen-reader-notice\" c...\n",
      "1603      <div id=\"js-global-screen-reader-notice-as...\n",
      "1604                                            </body>\n",
      "1605                                            </html>\n",
      "\n",
      "[1606 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mID</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>Doc</th>\n",
       "      <th>Com</th>\n",
       "      <th>Hor</th>\n",
       "      <th>Adv</th>\n",
       "      <th>Wes</th>\n",
       "      <th>Dra</th>\n",
       "      <th>Ani</th>\n",
       "      <th>...</th>\n",
       "      <th>Chi</th>\n",
       "      <th>Cri</th>\n",
       "      <th>Thr</th>\n",
       "      <th>Sci</th>\n",
       "      <th>Mys</th>\n",
       "      <th>Rom</th>\n",
       "      <th>Fil</th>\n",
       "      <th>Fan</th>\n",
       "      <th>Act</th>\n",
       "      <th>Mus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mID                        title  year  Doc  Com  Hor  Adv  Wes  Dra  Ani  \\\n",
       "0    1                    Toy Story  1995    0    1    0    0    0    0    1   \n",
       "1    2                      Jumanji  1995    0    0    0    1    0    0    0   \n",
       "2    3             Grumpier Old Men  1995    0    1    0    0    0    0    0   \n",
       "3    4            Waiting to Exhale  1995    0    1    0    0    0    1    0   \n",
       "4    5  Father of the Bride Part II  1995    0    1    0    0    0    0    0   \n",
       "\n",
       "   ...  Chi  Cri  Thr  Sci  Mys  Rom  Fil  Fan  Act  Mus  \n",
       "0  ...    1    0    0    0    0    0    0    0    0    0  \n",
       "1  ...    1    0    0    0    0    0    0    1    0    0  \n",
       "2  ...    0    0    0    0    0    1    0    0    0    0  \n",
       "3  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "4  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PCA:\n",
    "    def __init__(self, target_explained_variance=None):\n",
    "        self.target_explained_variance = target_explained_variance\n",
    "        self.feature_size = -1\n",
    "\n",
    "    def standardize(self, X):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        return scaler.fit_transform(X)\n",
    "\n",
    "    def compute_mean_vector(self, X_std):\n",
    "        return np.mean(X_std, axis=0)\n",
    "\n",
    "    def compute_cov(self, X_std, mean_vec):\n",
    "        m = X_std.shape[0]\n",
    "        X_centered = X_std - mean_vec\n",
    "        return (X_centered.T @ X_centered) / (m - 1)\n",
    "\n",
    "    def compute_eigen_vector(self, cov_mat):\n",
    "        eigen_values, eigen_vectors = np.linalg.eig(cov_mat)\n",
    "        return eigen_values, eigen_vectors\n",
    "\n",
    "    def compute_explained_variance(self, eigen_vals):\n",
    "        total = np.sum(eigen_vals)\n",
    "        explained_variance = eigen_vals / total\n",
    "        return explained_variance\n",
    "\n",
    "    def cumulative_sum(self, var_exp):\n",
    "        return np.cumsum(var_exp)\n",
    "\n",
    "    def compute_weight_matrix(self, eig_pairs, cum_var_exp):\n",
    "        cum_var_exp = np.array(cum_var_exp)\n",
    "        num_components = np.argmax(cum_var_exp >= self.target_explained_variance)\n",
    "        matrix_w = np.hstack(\n",
    "            [eig_pairs[i][1].reshape(-1, 1) for i in range(num_components)]\n",
    "        )\n",
    "        return matrix_w\n",
    "\n",
    "    def transform_data(self, X_std, matrix_w):\n",
    "        return X_std.dot(matrix_w)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.feature_size = X.shape[1]\n",
    "        X_std = self.standardize(X)\n",
    "        mean_vec = self.compute_mean_vector(X_std)\n",
    "        cov_mat = self.compute_cov(X_std, mean_vec)\n",
    "        eigen_vals, eigen_vecs = self.compute_eigen_vector(cov_mat)\n",
    "        explained_variance = self.compute_explained_variance(eigen_vals)\n",
    "        cum_var_exp = self.cumulative_sum(explained_variance)\n",
    "        eig_pairs = [(eigen_vals[i], eigen_vecs[:, i]) for i in range(len(eigen_vals))]\n",
    "        eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "        matrix_w = self.compute_weight_matrix(eig_pairs, cum_var_exp)\n",
    "        return self.transform_data(X_std=X_std, matrix_w=matrix_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>accupation</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uID gender  age  accupation    zip\n",
       "0    1      F    1          10  48067\n",
       "1    2      M   56          16  70072\n",
       "2    3      M   25          15  55117\n",
       "3    4      M   45           7  02460\n",
       "4    5      M   25          20  55455"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MV_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using matrix factorization technique , SVD Singular Value Decomposition to predict the missing ratings and evauluate model performance using RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.9135255789628096\n"
     ]
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "\n",
    "#We need to create a user-item matrix (matrix of ratings), where rows correspond to users, columns correspond to movies, and the values represent the ratings given by users to movies. \n",
    "#Missing ratings will be filled with zeros or a specific placeholder.\n",
    "\n",
    "# Create user-item matrix for the training data\n",
    "train_matrix = train.pivot(index='uID', columns='mID', values='rating').fillna(0)\n",
    "\n",
    "# Perform matrix factorization using NMF\n",
    "nmf = NMF(n_components=50, random_state=42)  # 50 latent features\n",
    "W = nmf.fit_transform(train_matrix)  # User matrix\n",
    "H = nmf.components_  # Item matrix\n",
    "\n",
    "# Reconstruct the matrix (approximating the missing values)\n",
    "reconstructed_matrix = np.dot(W, H)\n",
    "\n",
    "# Convert the reconstructed matrix into a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_matrix, columns=train_matrix.columns, index=train_matrix.index)\n",
    "\n",
    "# Handle test data prediction with missing user-item pairs gracefully\n",
    "predictions = []\n",
    "for _, row in test.iterrows():\n",
    "    uid, mid = row['uID'], row['mID']\n",
    "    \n",
    "    # Check if both uid and mid exist in the reconstructed matrix\n",
    "    if uid in reconstructed_df.index and mid in reconstructed_df.columns:\n",
    "        predicted_rating = reconstructed_df.loc[uid, mid]\n",
    "    else:\n",
    "        # If the pair is missing, use the average rating of all movies for this user\n",
    "        predicted_rating = reconstructed_df.loc[uid].mean() if uid in reconstructed_df.index else reconstructed_df.mean().mean()\n",
    "    \n",
    "    predictions.append(predicted_rating)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error) between predicted ratings and actual ratings\n",
    "actual_ratings = test['rating'].values\n",
    "rmse = sqrt(mean_squared_error(actual_ratings, predictions))\n",
    "\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF performance compared to simple baseline or similarity-based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So , RMSE of non-negative matrix factorization :2.9135255789628096\n",
    "and \n",
    "RMSE of Baseline model 1.2642784503423288 and Content-Based are 1.1962537249116723. The lower the RMSE, the better the model is at predicting ratings. \n",
    "\n",
    "This dataset contains sparse user-item ratings,meaning most users have rated only a small subset of available movies.\n",
    "\n",
    "Moreover,with many unique users (uID) and movies (mID), the matrix can be very large, making it computationally challenging to handle with matrix factorization methods like NMF unless you have enough data for training. \n",
    "\n",
    "Baseline methods  and similarity-based methods worked better because they leverage the observed ratings more effectively and are less sensitive to sparsity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
